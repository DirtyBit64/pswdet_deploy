# Ultralytics YOLO ğŸš€, AGPL-3.0 license
import onnxruntime
from ultralytics.engine.predictor import BasePredictor
from ultralytics.engine.results import Results
from ultralytics.utils import ops

from ultralytics.models.yolo.detect.roadseg.seg_utils import seg_filter


class DetectionPredictor(BasePredictor):
    """
    A class extending the BasePredictor class for prediction based on a detection model.

    Example:
        ```python
        from ultralytics.utils import ASSETS
        from ultralytics.models.yolo.detect import DetectionPredictor

        args = dict(model='yolov8n.pt', source=ASSETS)
        predictor = DetectionPredictor(overrides=args)
        predictor.predict_cli()
        ```
    """

    ###########################################
    # è®°å½•å•æ¬¡æ£€æµ‹è¿‡ç¨‹ä¸­boxæ•°ç›®
    box_count = 0

    # è®¾ç½®ONNXæ¨¡å‹è·¯å¾„
    ONNX_MODEL_PATH = 'ultralytics/models/yolo/detect/roadseg/pidnet.onnx'
    # seg_model = load_pretrained(get_pred_model(name='s', num_classes=2),
    #                             pretrained='ultralytics/models/yolo/detect/roadseg/pidnet.pt').cuda()
    # åŠ è½½onnxruntimeè§£é‡Šå™¨
    seg_model = onnxruntime.InferenceSession(ONNX_MODEL_PATH, None,
                                             providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])
    ###########################################

    def postprocess(self, preds, img, orig_imgs):
        """å¯¹å•ä¸ªé¢„æµ‹ç»“æœè¿›è¡Œåå¤„ç†å¹¶è¿”å›resultså¯¹è±¡é›†åˆ"""
        preds = ops.non_max_suppression(preds,
                                        self.args.conf,
                                        self.args.iou,
                                        agnostic=self.args.agnostic_nms,
                                        max_det=self.args.max_det,
                                        classes=self.args.classes)

        results = []
        is_list = isinstance(orig_imgs, list)  # input images are a list, not a torch.Tensor
        for i, pred in enumerate(preds):
            orig_img = orig_imgs[i] if is_list else orig_imgs
            if is_list:
                pred[:, :4] = ops.scale_boxes(img.shape[2:], pred[:, :4], orig_img.shape)
            img_path = self.batch[0][i]

            ###########################################
            # é‡‡ç”¨é“è·¯åˆ†å‰²æ©ç å¯¹nmsåçš„é¢„æµ‹æ¡†è¿›è¡ŒäºŒæ¬¡è¿‡æ»¤
            if self.args.seg_filter and pred.shape[0] != 0:
                pred = seg_filter(pred, orig_img, self.seg_model, prop=0.8)

            # æ£€æµ‹æ¡†è®¡æ•°
            self.box_count += pred.shape[0]
            # åŠ¨æ€è°ƒæ•´è¶…å‚ï¼Œæœ‰è¯¯æŠ¥æ‰ä¿å­˜
            if self.args.save_if_box_father:
                self.args.save_if_box = pred.shape[0] != 0

            ###########################################
            results.append(Results(orig_img, path=img_path, names=self.model.names, boxes=pred))

        ########################################
        print("å½“å‰æ€»æ£€æµ‹æ¡†æ•°ç›®: ", self.box_count)
        ########################################

        return results
