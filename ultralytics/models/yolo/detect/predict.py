# Ultralytics YOLO ğŸš€, AGPL-3.0 license
import onnxruntime
from ultralytics.engine.predictor import BasePredictor
from ultralytics.engine.results import Results
from ultralytics.utils import ops

from ultralytics.models.yolo.detect.roadseg.seg_utils import seg_filter
from ultralytics.models.yolo.detect.filtlercls.cls_utils import cls_filter
import numpy as np
import torch


class DetectionPredictor(BasePredictor):
    """
    A class extending the BasePredictor class for prediction based on a detection model.

    Example:
        ```python
        from ultralytics.utils import ASSETS
        from ultralytics.models.yolo.detect import DetectionPredictor

        args = dict(model='yolov8n.pt', source=ASSETS)
        predictor = DetectionPredictor(overrides=args)
        predictor.predict_cli()
        ```
    """

    ###########################################
    # è®°å½•å•æ¬¡æ£€æµ‹è¿‡ç¨‹ä¸­boxæ•°ç›®
    box_count = 0

    # åˆå§‹åŒ–åŠ è½½åˆ†å‰²æ¨¡å‹
    SEG_ONNX_MODEL_PATH = 'ultralytics/models/yolo/detect/roadseg/pidnet.onnx'
    seg_model = onnxruntime.InferenceSession(SEG_ONNX_MODEL_PATH, None,
                                             providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])
    # åˆå§‹åŒ–åŠ è½½åˆ†ç±»æ¨¡å‹
    CLS_ONNX_MODEL_PATH = 'ultralytics/models/yolo/detect/filtlercls/psw64a.onnx'
    cls_model = onnxruntime.InferenceSession(CLS_ONNX_MODEL_PATH, None,
                                             providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])

    # è®°å½•ä¸Šæ¬¡æ£€å‡ºçš„preds
    pre_boxes_np = []
    ###########################################

    def postprocess(self, preds, img, orig_imgs):
        """å¯¹å•ä¸ªé¢„æµ‹ç»“æœè¿›è¡Œåå¤„ç†å¹¶è¿”å›resultså¯¹è±¡é›†åˆ"""
        preds = ops.non_max_suppression(preds,
                                        self.args.conf,
                                        self.args.iou,
                                        agnostic=self.args.agnostic_nms,
                                        max_det=self.args.max_det,
                                        classes=self.args.classes)

        results = []
        is_list = isinstance(orig_imgs, list)  # input images are a list, not a torch.Tensor
        for i, pred in enumerate(preds):
            orig_img = orig_imgs[i] if is_list else orig_imgs
            if is_list:
                pred[:, :4] = ops.scale_boxes(img.shape[2:], pred[:, :4], orig_img.shape)
            img_path = self.batch[0][i]

            ###########################################
            # 1.é‡‡ç”¨é“è·¯åˆ†å‰²æ©ç å¯¹nmsåçš„é¢„æµ‹æ¡†è¿›è¡ŒäºŒæ¬¡è¿‡æ»¤
            if self.args.seg_filter and pred.shape[0] != 0:
                pred = seg_filter(pred, orig_img, self.seg_model, prop=0.8)

            # 2.åˆ©ç”¨åˆ†ç±»è¿‡æ»¤æ¨¡å‹å¯¹nmsåçš„é¢„æµ‹æ¡†è¿›è¡ŒäºŒæ¬¡è¿‡æ»¤
            if self.args.cls_filter and pred.shape[0] != 0:
                pred = cls_filter(self.cls_model, pred, orig_img, proportion=0.2)

            # 3.æ—¶åºiouå»é‡
            if self.args.frame_iou > 0 and pred.shape[0] != 0:
                pred = self.frame_iou_filter(pred)

            # æ£€æµ‹æ¡†è®¡æ•°
            self.box_count += pred.shape[0]
            # åŠ¨æ€è°ƒæ•´è¶…å‚ï¼Œæœ‰è¯¯æŠ¥æ‰ä¿å­˜
            if self.args.save_if_box_father:
                self.args.save_if_box = pred.shape[0] != 0

            ###########################################
            results.append(Results(orig_img, path=img_path, names=self.model.names, boxes=pred))

        ########################################
        print("å½“å‰æ€»æ£€æµ‹æ¡†æ•°ç›®: ", self.box_count)
        ########################################

        return results

    def frame_iou_filter(self, pred):
        """
            å‡å°‘æ—¶åºé‡å¤æ£€æµ‹ï¼Œç”¨äºè§†é¢‘æµ
                @pred å½“å‰å¸§çš„æ£€æµ‹ç»“æœ
        """
        if self.args.frame_iou > 1:
            raise ValueError("frame_ioué˜ˆå€¼å¿…é¡»åœ¨0-1çš„èŒƒå›´å†…")

        boxes_np = pred.cpu().numpy()

        # æ‹·è´å‰¯æœ¬
        temp_pre_boxes = self.pre_boxes_np.copy()
        temp_boxes_np = boxes_np.copy()

        # æ›´æ–°pre_boxes_np
        self.pre_boxes_np = boxes_np

        # åŸºäºmaskè¿‡æ»¤æ£€æµ‹æ¡†
        r = 0
        for box_np in temp_boxes_np:  # (x1,y1,x2,y2,conf,cls)
            is_del = False
            for pre_box_np in temp_pre_boxes:
                # ç±»åˆ«ä¸ä¸€æ ·è·³è¿‡
                if box_np[5] != pre_box_np[5]:
                    continue

                # å‹ç¼©æˆx1x2y1y2æ–¹ä¾¿è®¡ç®—iou
                box1 = np.array([box_np[0], box_np[1], box_np[2], box_np[3]])
                box2 = np.array([pre_box_np[0], pre_box_np[1], pre_box_np[2], pre_box_np[3]])

                if calculate_iou(box1, box2) >= self.args.frame_iou:
                    boxes_np = np.delete(boxes_np, r, axis=0)
                    is_del = True
                    break

            if not is_del:
                r += 1

        # è¿”å›è¿‡æ»¤åçš„Tensor.cuda()ç±»å‹ç»“æœ
        return torch.tensor(boxes_np).cuda()


# fromæ–‡å¿ƒä¸€è¨€
# è®¡ç®—ä¸¤ä¸ªæ¡†çš„iou,æ³¨æ„boxè¦æ˜¯numpyæ•°ç»„
def calculate_iou(box1, box2):
    # è·å–ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„åæ ‡
    x1, y1, x2, y2 = box1
    x3, y3, x4, y4 = box2

    # è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†äº¤é›†çš„å·¦ä¸Šå’Œå³ä¸‹åæ ‡
    inter_x1 = max(x1, x3)
    inter_y1 = max(y1, y3)
    inter_x2 = min(x2, x4)
    inter_y2 = min(y2, y4)

    # è®¡ç®—äº¤é›†é¢ç§¯ï¼Œå¦‚æœäº¤é›†ä¸å­˜åœ¨åˆ™é¢ç§¯ä¸º0
    if inter_x2 - inter_x1 < 0 or inter_y2 - inter_y1 < 0:
        intersection_area = 0
    else:
        intersection_area = (inter_x2 - inter_x1) * (inter_y2 - inter_y1)

    # è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„å¹¶é›†é¢ç§¯
    box1_area = (x2 - x1) * (y2 - y1)
    box2_area = (x4 - x3) * (y4 - y3)
    union_area = box1_area + box2_area - intersection_area

    # è®¡ç®—IoU
    iou = intersection_area / union_area

    return iou
